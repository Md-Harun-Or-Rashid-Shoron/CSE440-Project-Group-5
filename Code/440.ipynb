{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda789c7-38f6-42a7-a0b2-e4744923f768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Metrics:\n",
      "Accuracy: 0.64\n",
      "Precision: 0.6441176470588236\n",
      "Recall: 0.4375\n",
      "F1 Score: 0.4222794222794222\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.84\n",
      "Precision: 0.8194570287593543\n",
      "Recall: 0.7892441860465116\n",
      "F1 Score: 0.7912253338609928\n",
      "\n",
      "Bagging Metrics:\n",
      "Accuracy: 0.88\n",
      "Precision: 0.8409738409738411\n",
      "Recall: 0.8255813953488372\n",
      "F1 Score: 0.8296146044624746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masum\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('Sleep_health_and_lifestyle_dataset.csv')\n",
    "\n",
    "# Label encoding\n",
    "label_encoders = {}\n",
    "for column in ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split the data\n",
    "X = data.drop('Sleep Disorder', axis=1)\n",
    "y = data['Sleep Disorder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# SVM\n",
    "clf_svm = SVC(random_state=42)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm, average='macro')\n",
    "recall_svm = recall_score(y_test, y_pred_svm, average='macro')\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "\n",
    "# Logistic Regression\n",
    "clf_lr = LogisticRegression(random_state=42)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='macro')\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='macro')\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "# Bagging\n",
    "clf_bagging = BaggingClassifier(random_state=42)\n",
    "clf_bagging.fit(X_train, y_train)\n",
    "y_pred_bagging = clf_bagging.predict(X_test)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "precision_bagging = precision_score(y_test, y_pred_bagging, average='macro')\n",
    "recall_bagging = recall_score(y_test, y_pred_bagging, average='macro')\n",
    "f1_bagging = f1_score(y_test, y_pred_bagging, average='macro')\n",
    "\n",
    "# Print metrics\n",
    "print(\"SVM Metrics:\\nAccuracy: {}\\nPrecision: {}\\nRecall: {}\\nF1 Score: {}\".format(accuracy_svm, precision_svm, recall_svm, f1_svm))\n",
    "print(\"\\nLogistic Regression Metrics:\\nAccuracy: {}\\nPrecision: {}\\nRecall: {}\\nF1 Score: {}\".format(accuracy_lr, precision_lr, recall_lr, f1_lr))\n",
    "print(\"\\nBagging Metrics:\\nAccuracy: {}\\nPrecision: {}\\nRecall: {}\\nF1 Score: {}\".format(accuracy_bagging, precision_bagging, recall_bagging, f1_bagging))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825dfd56-814c-4bc5-90c6-c501710b4059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and split successfully. Shape of train set: (299, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'D:\\Sleep_health_and_lifestyle_dataset.csv')\n",
    "\n",
    "# Label encoding\n",
    "for column in ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']:\n",
    "    data[column] = LabelEncoder().fit_transform(data[column])\n",
    "\n",
    "# Split the data\n",
    "X = data.drop('Sleep Disorder', axis=1)\n",
    "y = data['Sleep Disorder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"Data loaded and split successfully. Shape of train set:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a66afe8-5f87-4203-b3b6-e85ae0cc4c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] END ................max_depth=None, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ................max_depth=None, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ................max_depth=None, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ................max_depth=None, min_samples_split=5; total time=   0.0s\n",
      "[CV] END ................max_depth=None, min_samples_split=5; total time=   0.0s\n",
      "[CV] END ................max_depth=None, min_samples_split=5; total time=   0.0s\n",
      "[CV] END ...............max_depth=None, min_samples_split=10; total time=   0.0s\n",
      "[CV] END ...............max_depth=None, min_samples_split=10; total time=   0.0s\n",
      "[CV] END ...............max_depth=None, min_samples_split=10; total time=   0.0s\n",
      "[CV] END ..................max_depth=10, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ..................max_depth=10, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ..................max_depth=10, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ..................max_depth=10, min_samples_split=5; total time=   0.0s\n",
      "[CV] END ..................max_depth=10, min_samples_split=5; total time=   0.0s\n",
      "[CV] END ..................max_depth=10, min_samples_split=5; total time=   0.0s\n",
      "[CV] END .................max_depth=10, min_samples_split=10; total time=   0.0s\n",
      "[CV] END .................max_depth=10, min_samples_split=10; total time=   0.0s\n",
      "[CV] END .................max_depth=10, min_samples_split=10; total time=   0.0s\n",
      "[CV] END ..................max_depth=20, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ..................max_depth=20, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ..................max_depth=20, min_samples_split=2; total time=   0.0s\n",
      "[CV] END ..................max_depth=20, min_samples_split=5; total time=   0.0s\n",
      "[CV] END ..................max_depth=20, min_samples_split=5; total time=   0.0s\n",
      "[CV] END ..................max_depth=20, min_samples_split=5; total time=   0.0s\n",
      "[CV] END .................max_depth=20, min_samples_split=10; total time=   0.0s\n",
      "[CV] END .................max_depth=20, min_samples_split=10; total time=   0.0s\n",
      "[CV] END .................max_depth=20, min_samples_split=10; total time=   0.0s\n",
      "Decision Tree best parameters: {'max_depth': None, 'min_samples_split': 2}\n",
      "Decision Tree accuracy: 0.9066666666666666\n",
      "Decision Tree precision: 0.8750661375661376\n",
      "Decision Tree recall: 0.8541666666666666\n",
      "Decision Tree F1 Score: 0.8632575757575758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_dt = {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid_dt, cv=3, verbose=2)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_dt = grid_dt.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt, average='macro')\n",
    "recall_dt = recall_score(y_test, y_pred_dt, average='macro')\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='macro')\n",
    "\n",
    "# Print results\n",
    "print(\"Decision Tree best parameters:\", grid_dt.best_params_)\n",
    "print(\"Decision Tree accuracy:\", accuracy_dt)\n",
    "print(\"Decision Tree precision:\", precision_dt)\n",
    "print(\"Decision Tree recall:\", recall_dt)\n",
    "print(\"Decision Tree F1 Score:\", f1_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d8a03b-bc8d-459f-97a8-ff3f1022f4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=150; total time=   0.1s\n",
      "Random Forest best parameters: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 150}\n",
      "Random Forest accuracy: 0.88\n",
      "Random Forest precision: 0.8409738409738411\n",
      "Random Forest recall: 0.8255813953488372\n",
      "Random Forest F1 Score: 0.8296146044624746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV for Random Forest\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=3, verbose=2)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='macro')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='macro')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "\n",
    "# Print results\n",
    "print(\"Random Forest best parameters:\", grid_rf.best_params_)\n",
    "print(\"Random Forest accuracy:\", accuracy_rf)\n",
    "print(\"Random Forest precision:\", precision_rf)\n",
    "print(\"Random Forest recall:\", recall_rf)\n",
    "print(\"Random Forest F1 Score:\", f1_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb346ae-1b8d-4f6e-a1dd-ec62d33831f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=euclidean, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=euclidean, n_neighbors=10, weights=uniform; total time=   0.0s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   0.0s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   0.0s\n",
      "[CV] END .metric=euclidean, n_neighbors=10, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=3, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=3, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=5, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=5, weights=distance; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ...metric=manhattan, n_neighbors=7, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=7, weights=distance; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=   0.0s\n",
      "[CV] END ..metric=manhattan, n_neighbors=10, weights=uniform; total time=   0.0s\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=   0.0s\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=   0.0s\n",
      "[CV] END .metric=manhattan, n_neighbors=10, weights=distance; total time=   0.0s\n",
      "KNN best parameters: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
      "KNN accuracy: 0.88\n",
      "KNN precision: 0.8409738409738411\n",
      "KNN recall: 0.8255813953488372\n",
      "KNN F1 Score: 0.8296146044624746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 10],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV for KNN\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=3, verbose=2)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_knn = grid_knn.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_knn = best_knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn, average='macro')\n",
    "recall_knn = recall_score(y_test, y_pred_knn, average='macro')\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='macro')\n",
    "\n",
    "# Print results\n",
    "print(\"KNN best parameters:\", grid_knn.best_params_)\n",
    "print(\"KNN accuracy:\", accuracy_knn)\n",
    "print(\"KNN precision:\", precision_knn)\n",
    "print(\"KNN recall:\", recall_knn)\n",
    "print(\"KNN F1 Score:\", f1_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc4e464-c743-41d5-bfc0-8a11368fcc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "SVM best parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVM accuracy: 0.88\n",
      "SVM precision: 0.8837868480725622\n",
      "SVM recall: 0.8125\n",
      "SVM F1 Score: 0.8401656314699794\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'D:\\Sleep_health_and_lifestyle_dataset.csv')  # Adjust the path as necessary\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Splitting data\n",
    "X = data.drop('Sleep Disorder', axis=1)\n",
    "y = data['Sleep Disorder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define a simpler parameter grid for SVM\n",
    "param_grid_svm = {\n",
    "    'C': [1, 10],  # Regularization parameter\n",
    "    'kernel': ['rbf'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV for SVM with reduced CV folds\n",
    "grid_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=2, verbose=2)  # Reduced from 3 to 2 folds for speed\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_svm = grid_svm.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm, average='macro')\n",
    "recall_svm = recall_score(y_test, y_pred_svm, average='macro')\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "\n",
    "# Print results\n",
    "print(\"SVM best parameters:\", grid_svm.best_params_)\n",
    "print(\"SVM accuracy:\", accuracy_svm)\n",
    "print(\"SVM precision:\", precision_svm)\n",
    "print(\"SVM recall:\", recall_svm)\n",
    "print(\"SVM F1 Score:\", f1_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27c05aca-1d6a-4770-884c-fb6d4a30e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV] END .max_features=0.5, max_samples=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=0.5, max_samples=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=0.5, max_samples=0.5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_features=0.5, max_samples=0.5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=0.5, max_samples=0.5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=0.5, max_samples=0.5, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_features=0.5, max_samples=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=0.5, max_samples=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=0.5, max_samples=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_features=0.5, max_samples=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=0.5, max_samples=1.0, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=0.5, max_samples=1.0, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_features=1.0, max_samples=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=1.0, max_samples=0.5, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=1.0, max_samples=0.5, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_features=1.0, max_samples=0.5, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=1.0, max_samples=0.5, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=1.0, max_samples=0.5, n_estimators=100; total time=   0.1s\n",
      "[CV] END .max_features=1.0, max_samples=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=1.0, max_samples=1.0, n_estimators=10; total time=   0.0s\n",
      "[CV] END .max_features=1.0, max_samples=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV] END .max_features=1.0, max_samples=1.0, n_estimators=50; total time=   0.0s\n",
      "[CV] END max_features=1.0, max_samples=1.0, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_features=1.0, max_samples=1.0, n_estimators=100; total time=   0.1s\n",
      "Bagging Classifier best parameters: {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 50}\n",
      "Bagging Classifier accuracy: 0.88\n",
      "Bagging Classifier precision: 0.8409738409738411\n",
      "Bagging Classifier recall: 0.8255813953488372\n",
      "Bagging Classifier F1 Score: 0.8296146044624746\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'D:\\Sleep_health_and_lifestyle_dataset.csv')  # Adjust the path as necessary\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Splitting data\n",
    "X = data.drop('Sleep Disorder', axis=1)\n",
    "y = data['Sleep Disorder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Define parameter grid for Bagging Classifier\n",
    "param_grid_bagging = {\n",
    "    'n_estimators': [10, 50, 100],  # Number of base estimators in the ensemble\n",
    "    'max_samples': [0.5, 1.0],  # The maximum number of samples to train each base estimator\n",
    "    'max_features': [0.5, 1.0]  # The maximum number of features to draw from X to train each base estimator\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV for Bagging Classifier\n",
    "grid_bagging = GridSearchCV(BaggingClassifier(random_state=42), param_grid_bagging, cv=2, verbose=2)  # Using 2 folds for speed\n",
    "grid_bagging.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_bagging = grid_bagging.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_bagging = best_bagging.predict(X_test)\n",
    "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
    "precision_bagging = precision_score(y_test, y_pred_bagging, average='macro')\n",
    "recall_bagging = recall_score(y_test, y_pred_bagging, average='macro')\n",
    "f1_bagging = f1_score(y_test, y_pred_bagging, average='macro')\n",
    "\n",
    "# Print results\n",
    "print(\"Bagging Classifier best parameters:\", grid_bagging.best_params_)\n",
    "print(\"Bagging Classifier accuracy:\", accuracy_bagging)\n",
    "print(\"Bagging Classifier precision:\", precision_bagging)\n",
    "print(\"Bagging Classifier recall:\", recall_bagging)\n",
    "print(\"Bagging Classifier F1 Score:\", f1_bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6189e7f4-fe7d-48ca-a6c1-cdf72ac92ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV] END ..............C=0.1, max_iter=200, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=0.1, max_iter=200, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, max_iter=200, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=0.1, max_iter=200, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..............C=0.1, max_iter=400, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..............C=0.1, max_iter=400, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, max_iter=400, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ..................C=0.1, max_iter=400, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................C=1, max_iter=200, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=1, max_iter=200, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=200, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ................C=1, max_iter=400, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=1, max_iter=400, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ....................C=1, max_iter=400, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............C=10, max_iter=200, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, max_iter=200, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=200, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...............C=10, max_iter=400, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=10, max_iter=400, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, solver=lbfgs; total time=   0.0s\n",
      "[CV] END ...................C=10, max_iter=400, solver=lbfgs; total time=   0.0s\n",
      "Logistic Regression best parameters: {'C': 1, 'max_iter': 200, 'solver': 'liblinear'}\n",
      "Logistic Regression accuracy: 0.88\n",
      "Logistic Regression precision: 0.8633838621598718\n",
      "Logistic Regression recall: 0.8517441860465116\n",
      "Logistic Regression F1 Score: 0.8526062550120289\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r'D:\\Sleep_health_and_lifestyle_dataset.csv')\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in ['Gender', 'Occupation', 'BMI Category', 'Blood Pressure', 'Sleep Disorder']:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Splitting data\n",
    "X = data.drop('Sleep Disorder', axis=1)\n",
    "y = data['Sleep Disorder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define parameter grid for Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs'],  # Algorithm to use in the optimization problem\n",
    "    'max_iter': [200, 400]  # Increased maximum number of iterations\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV for Logistic Regression\n",
    "grid_lr = GridSearchCV(LogisticRegression(random_state=42), param_grid_lr, cv=2, verbose=2)\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "# Prediction and evaluation\n",
    "y_pred_lr = best_lr.predict(X_test_scaled)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, average='macro')\n",
    "recall_lr = recall_score(y_test, y_pred_lr, average='macro')\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "\n",
    "# Print results\n",
    "print(\"Logistic Regression best parameters:\", grid_lr.best_params_)\n",
    "print(\"Logistic Regression accuracy:\", accuracy_lr)\n",
    "print(\"Logistic Regression precision:\", precision_lr)\n",
    "print(\"Logistic Regression recall:\", recall_lr)\n",
    "print(\"Logistic Regression F1 Score:\", f1_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050ce82-9f96-4219-a04c-c2074ddc8867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
